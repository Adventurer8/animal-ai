[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0
[INFO] Connected new brain: AnimalAI?team=0
[WARNING] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
/home/roma/.local/lib/python3.10/site-packages/gym/logger.py:34: UserWarning: [33mWARN: Box bound precision lowered by casting to float32
  warnings.warn(colorize("%s: %s" % ("WARN", msg % args), "yellow"))
/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:219: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 7.79GB > 1.94GB
  warnings.warn(
Logging to ./dqn_tensorboard/inserrunname/DQN_2
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.984    |
| time/               |          |
|    episodes         | 4        |
|    fps              | 117      |
|    time_elapsed     | 14       |
|    total timesteps  | 1668     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.968    |
| time/               |          |
|    episodes         | 8        |
|    fps              | 118      |
|    time_elapsed     | 28       |
|    total timesteps  | 3336     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.952    |
| time/               |          |
|    episodes         | 12       |
|    fps              | 116      |
|    time_elapsed     | 43       |
|    total timesteps  | 5004     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.937    |
| time/               |          |
|    episodes         | 16       |
|    fps              | 117      |
|    time_elapsed     | 56       |
|    total timesteps  | 6672     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.921    |
| time/               |          |
|    episodes         | 20       |
|    fps              | 118      |
|    time_elapsed     | 70       |
|    total timesteps  | 8340     |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.905    |
| time/               |          |
|    episodes         | 24       |
|    fps              | 118      |
|    time_elapsed     | 84       |
|    total timesteps  | 10008    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.889    |
| time/               |          |
|    episodes         | 28       |
|    fps              | 119      |
|    time_elapsed     | 97       |
|    total timesteps  | 11676    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.873    |
| time/               |          |
|    episodes         | 32       |
|    fps              | 119      |
|    time_elapsed     | 111      |
|    total timesteps  | 13344    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.857    |
| time/               |          |
|    episodes         | 36       |
|    fps              | 120      |
|    time_elapsed     | 125      |
|    total timesteps  | 15012    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.842    |
| time/               |          |
|    episodes         | 40       |
|    fps              | 120      |
|    time_elapsed     | 138      |
|    total timesteps  | 16680    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.826    |
| time/               |          |
|    episodes         | 44       |
|    fps              | 120      |
|    time_elapsed     | 152      |
|    total timesteps  | 18348    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.81     |
| time/               |          |
|    episodes         | 48       |
|    fps              | 120      |
|    time_elapsed     | 166      |
|    total timesteps  | 20016    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.794    |
| time/               |          |
|    episodes         | 52       |
|    fps              | 120      |
|    time_elapsed     | 180      |
|    total timesteps  | 21684    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.778    |
| time/               |          |
|    episodes         | 56       |
|    fps              | 120      |
|    time_elapsed     | 193      |
|    total timesteps  | 23352    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.762    |
| time/               |          |
|    episodes         | 60       |
|    fps              | 120      |
|    time_elapsed     | 207      |
|    total timesteps  | 25020    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.746    |
| time/               |          |
|    episodes         | 64       |
|    fps              | 120      |
|    time_elapsed     | 221      |
|    total timesteps  | 26688    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.731    |
| time/               |          |
|    episodes         | 68       |
|    fps              | 120      |
|    time_elapsed     | 234      |
|    total timesteps  | 28356    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.715    |
| time/               |          |
|    episodes         | 72       |
|    fps              | 120      |
|    time_elapsed     | 248      |
|    total timesteps  | 30024    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.699    |
| time/               |          |
|    episodes         | 76       |
|    fps              | 120      |
|    time_elapsed     | 262      |
|    total timesteps  | 31692    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.683    |
| time/               |          |
|    episodes         | 80       |
|    fps              | 120      |
|    time_elapsed     | 276      |
|    total timesteps  | 33360    |
----------------------------------
----------------------------------
| rollout/            |          |
|    ep_len_mean      | 417      |
|    ep_rew_mean      | -0.999   |
|    exploration rate | 0.667    |
| time/               |          |
|    episodes         | 84       |
|    fps              | 120      |
|    time_elapsed     | 290      |
|    total timesteps  | 35028    |
----------------------------------
Traceback (most recent call last):
  File "/home/roma/animal-ai/examples/gymwrapper.py", line 75, in <module>
  File "/home/roma/animal-ai/examples/gymwrapper.py", line 59, in train_agent_single_config
    help="the batch size of sample from the reply memory")
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py", line 241, in learn
    return super(DQN, self).learn(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 352, in learn
    rollout = self.collect_rollouts(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 571, in collect_rollouts
    new_obs, reward, done, infos = env.step(action)
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
    return self.step_wait()
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 83, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 90, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/roma/.local/lib/python3.10/site-packages/gym_unity/envs/__init__.py", line 201, in step
    self._env.step()
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/timers.py", line 305, in wrapped
    return func(*args, **kwargs)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/environment.py", line 348, in step
    outputs = self._communicator.exchange(step_input, self._poll_process)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py", line 142, in exchange
    self.poll_for_timeout(poll_callback)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py", line 106, in poll_for_timeout
    if self.unity_to_external.parent_conn.poll(callback_timeout_wait):
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 923, in wait
    with _WaitSelector() as selector:
  File "/usr/lib/python3.10/selectors.py", line 349, in __init__
    super().__init__()
  File "/usr/lib/python3.10/selectors.py", line 214, in __init__
    self._map = _SelectorMapping(self)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/roma/animal-ai/examples/gymwrapper.py", line 75, in <module>
  File "/home/roma/animal-ai/examples/gymwrapper.py", line 59, in train_agent_single_config
    help="the batch size of sample from the reply memory")
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py", line 241, in learn
    return super(DQN, self).learn(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 352, in learn
    rollout = self.collect_rollouts(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 571, in collect_rollouts
    new_obs, reward, done, infos = env.step(action)
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
    return self.step_wait()
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 83, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "/home/roma/.local/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 90, in step
    observation, reward, done, info = self.env.step(action)
  File "/home/roma/.local/lib/python3.10/site-packages/gym_unity/envs/__init__.py", line 201, in step
    self._env.step()
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/timers.py", line 305, in wrapped
    return func(*args, **kwargs)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/environment.py", line 348, in step
    outputs = self._communicator.exchange(step_input, self._poll_process)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py", line 142, in exchange
    self.poll_for_timeout(poll_callback)
  File "/home/roma/.local/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py", line 106, in poll_for_timeout
    if self.unity_to_external.parent_conn.poll(callback_timeout_wait):
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 923, in wait
    with _WaitSelector() as selector:
  File "/usr/lib/python3.10/selectors.py", line 349, in __init__
    super().__init__()
  File "/usr/lib/python3.10/selectors.py", line 214, in __init__
    self._map = _SelectorMapping(self)
KeyboardInterrupt
Exception ignored in: <module 'threading' from '/usr/lib/python3.10/threading.py'>
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1537, in _shutdown
    atexit_call()
  File "/usr/lib/python3.10/concurrent/futures/thread.py", line 31, in _python_exit
    t.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt: